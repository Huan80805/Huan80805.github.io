<h1 class="project-title">GenAI Safety Assessment</h1>
                
<div class="about-text">
    <h2 class="h3">Description </h2>
    <p>
        This is a project funded by Taiwan's National Institute of Cyber Security.
        <br/>In this project, we aimed to <b>evaluate safety and security of Taiwanese LLMs</b>, including TAIDE and Taiwan-LLM.
        <br/>Our framework consists of two main components, building safeguard models and automatic redteaming.
    </p>
    <h2 class="h3">Safeguard Models</h2>
    <p>The goal of safeguard models is to accurately flag harmful content in LLMs' generations. 
        From preliminary experiment, we discovered that opensourced safeguard model, including LlamaGuard and ShieldLM, are insensitive to cultural-specific taboos and local expressions.
        To build a safeguard model for Taiwanese LLMs, we collected data from three sources:
    </p>
    <div class="image-gallery">
        <figure class="gallery-figure">
            <img src="assets/images/genaiSafety/pipeline.png" alt="dashboard" loading="lazy" style="width: 50%;">
            <figcaption style="text-align: center;">1. Toxic comments crawled from Taiwanese online forums. This figure shows how we collected and labelled toxic commencts.</figcaption>
        </figure>
    </div>
    <div class="image-gallery">
        <figure class="gallery-figure">
            <img src="assets/images/genaiSafety/sg2.png" alt="dashboard" loading="lazy">
            <figcaption>2. Existing Human-LLM conversation data, translated into Traditional Chinese. Source includes <a class="inline-ref" href="https://huggingface.co/datasets/Anthropic/hh-rlhf">Anthropic's hh-rlhf </a>
                and <a class="inline-ref" href="https://github.com/thu-coai/ShieldLM">ShieldLM training data.</a>
            </figcaption>
        </figure>
    </div>
    <div class="image-gallery">
        <figure class="gallery-figure">
            <img src="assets/images/genaiSafety/sg3.png" alt="dashboard" loading="lazy">
            <figcaption>3. We used (1) manully-designed prompts and (2) existing attack prompts to prompt Taiwanese LLMs and used ShiledLM, GPT-4, and LlamaGuard to automatically label responses.
            </figcaption>
        </figure>
    </div>
    <p>Our model performed better than LlamaGuard by F1-score 0.14. on flagging Taiwanese LLMs' generations, see some demo examples below</p>
    <div style="display: grid; width: 80%; aspect-ratio: 560/315; overflow: hidden; grid-template-columns: 1fr; border-radius: 16px; margin-top: 20px; margin-bottom: 20px;">
        <video width="100%" controls>
            <source src="assets/images/genaiSafety/sg_demo.mov" type="video/mp4">
        </video>
    </div>
    <h2 class="h3">Automatic Redteaming</h2>
    <p>In automatic redteaming, we aimed to probe LLMs' vulnerabilities through automatically generating adversarial attacks. We conducted two adversarial attacks under two different scenarios.</br>(Examples are redacted for safety issues)</p>
    <h2 class="h4">Black-box attacks</h2>
    <p>
        To attack a model we have no access to, we utilized RL to fine-tune an attacker for attacking victim. The reward is the given by our safeguard model.
        Throughout the process, the attacker can be guided to generate more effective attack prompts
    </p>
    <h2 class="h4">White-box attacks</h2>
    <p>
        Having access to model's gradient, we followed GCG to optimize adversarial suffix. The objective is to manipulate victim LLM to generate specific harmful string.
        On top of GCG's original objective, we additionally incorporated language modeling loss in order to generate sensible suffix.
    </p>
    <div class="image-gallery">
        <figure class="gallery-figure">
            <img src="assets/images/genaiSafety/red_black.png" alt="dashboard" loading="lazy">
            <figcaption>The framework of black-box red-teaming
            </figcaption>
        </figure>
        <figure class="gallery-figure">
            <img src="assets/images/genaiSafety/red_white.png" alt="dashboard" loading="lazy">
            <figcaption>The framework of white-box red-teaming
            </figcaption>
        </figure>
    </div>
</div>